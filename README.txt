Naive Bayes implementation to classify spam email.

Implementation Description:

The project contains 3 Java files: NaiveBayesClassifier.java, VocabInfo.java, and WordInfo.java. A WordInfo object contains information about a single word in the data, including the number of times it occurs in each class and the conditional probability of the word given a class. A VocabInfo object contains the vocabulary and information about the data. The vocabulary is represented as a HashMap that maps a word to its WordInfo object. VocabInfo also contains a HashMap that maps a class from the set {“spam” , “ham”} to the number of distinct word positions in the class, which is used in the conditional probability calculation. Finally, VocabInfo contains the probabilities of each class.The main method is in NaiveBayesClassifier. It simply calls two methods subsequently, learn() and classify(). If takes the smoothing parameter for the m-estimate as an argument. If no argument is given, then the default of the vocabulary size is used. If multiple arguments are given, the program is run separately for each.The learn() method reads each training example, incrementing the counter for its respective class occurrence and then adding its word instances to the vocabulary in VocabInfo. Once the entire file is read, the probabilities of the classes can be computed. Then conditional probability of each word given each class is computed. The method for computing these values are contained within the VocabInfo class, so the code in learn() in NaiveBayesClassifier shows the steps of the algorithm relatively clearly.In VocabInfo, the add() method is used for adding words to the vocabulary. If the word has already been seen, then it simply increments the word count for the appropriate class within the WordInfo object that represents that word. Otherwise, it constructs a new one.The computeCondProb() method is used to determine the conditional probability of each word given each class. It uses the formula given in the slides and text and takes the smoothing value as an argument. The value -1 is used to indicate the default, which is the size of the vocabulary. Both VocabInfo and WordInfo contain a few get and set methods that are self explanatory.For each test example, the classify() method in NaiveBayesClassifier implements the naive bayes text classification algorithm described in the test and slides. For each class, it computes the probability of that class times the conditional probability of each word in the test example given that class. The algorithm states to compute this for each word position. Since the data provides each distinct word followed by the number of times it occurs, the conditional probability is multiplied by that count. In order to avoid underflow, the sum of logs of the probabilities is computed instead of the product of the probabilities.

Format for training and testing data files:

[example id] [class] [word] [number of occurrences of word] [word] [number of occurrences of word] ...
[example id] [class] [word] [number of occurrences of word] [word] [number of occurrences of word] ...
…

Example:
01 spam this 1 email 1 is 1 spam 1
02 ham this 1 email 1 is 1 not 1 spam 1
